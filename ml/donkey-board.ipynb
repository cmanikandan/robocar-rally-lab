{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "... because it can help you understand your model better, find bugs and because it's cool.\n",
    "\n",
    "## Tensorboard\n",
    "\n",
    "There is a nifty tool from Google/TensorFlow used for exactly this purpose; [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard). What's even better is that there is support for it in SageMaker, it's even pre-installed when chosing the tensorflow kernel!\n",
    "\n",
    "To use it, we have to make additions to our training (and model). This is no problem, since we now define everything in our SageMaker notebooks =)\n",
    "\n",
    "## Re-create the model\n",
    "\n",
    "Let's start with recreating the model from the [previous chapter](./donkey-cloud-train.ipynb), but with some `TensorBoard` additions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "class MyEstimator():\n",
    "    '''\n",
    "    The Estimator creates and trains the model.\n",
    "    \n",
    "    Renamed from MyPilot.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.model = default_categorical()\n",
    "\n",
    "    def train(self, train_gen, val_gen, saved_model_path, log_path,\n",
    "              epochs=100, steps=100, train_split=0.8, verbose=1,\n",
    "              min_delta=.0005, patience=5, use_early_stop=True):\n",
    "\n",
    "        save_best = ModelCheckpoint(saved_model_path, \n",
    "                                    monitor='val_loss', \n",
    "                                    verbose=verbose, \n",
    "                                    save_best_only=True, \n",
    "                                    mode='min')\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_loss', \n",
    "                                   min_delta=min_delta, \n",
    "                                   patience=patience, \n",
    "                                   verbose=verbose, \n",
    "                                   mode='auto')\n",
    "        \n",
    "        # Add the Keras TensorBoard Callback\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n",
    "        tensorboard = TensorBoard (log_dir=log_path,\n",
    "                                   histogram_freq=0,\n",
    "                                   batch_size=32,\n",
    "                                   write_graph=True,\n",
    "                                   write_grads=False,\n",
    "                                   write_images=False)\n",
    "\n",
    "        callbacks_list = [save_best, tensorboard]\n",
    "\n",
    "        if use_early_stop:\n",
    "            callbacks_list.append(early_stop)\n",
    "        \n",
    "        hist = self.model.fit_generator(\n",
    "                        train_gen, \n",
    "                        steps_per_epoch=steps, \n",
    "                        epochs=epochs, \n",
    "                        verbose=verbose, \n",
    "                        validation_data=val_gen,\n",
    "                        callbacks=callbacks_list, \n",
    "                        validation_steps=steps*(1.0 - train_split))\n",
    "        return hist\n",
    "\n",
    "def default_categorical(): \n",
    "    from tensorflow.python.keras.models import Model\n",
    "    from tensorflow.python.keras.layers import Convolution2D\n",
    "    from tensorflow.python.keras.layers import Input, Dropout, Flatten, Dense\n",
    "    \n",
    "    img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "    x = img_in\n",
    "\n",
    "    x = Convolution2D(24, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (3,3), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (3,3), strides=(1,1), activation='relu')(x)\n",
    "\n",
    "    x = Flatten(name='flattened')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "\n",
    "    angle_out = Dense(15, activation='softmax', name='angle_out')(x)\n",
    "    throttle_out = Dense(1, activation='relu', name='throttle_out')(x)\n",
    "    \n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'angle_out': 'categorical_crossentropy', 'throttle_out': 'mean_absolute_error'},\n",
    "                  loss_weights={'angle_out': 0.9, 'throttle_out': .001})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "### Install Donkey (again)\n",
    "\n",
    "Reinstall (again) to be sure it is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone donkey git\n",
    "%cd ~/SageMaker\n",
    "!rm -rf ~/SageMaker/donkey\n",
    "!git clone https://github.com/wroscoe/donkey\n",
    "\n",
    "# Donkey has dependencies to tensorflow (non-GPU) and keras, none of which we are interested in.\n",
    "# Remove Keras and replace tensorflow with tensorflow-gpu\n",
    "!sed -i -e '/keras==2.0.8/d' donkey/setup.py\n",
    "!sed -i -e 's/tensorflow>=1.1/tensorflow-gpu>=1.4/g' donkey/setup.py\n",
    "\n",
    "# Install Donkey\n",
    "!pip uninstall donkeycar --yes\n",
    "!pip install ./donkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some globals for now\n",
    "BATCH_SIZE = 128\n",
    "TEST_SPLIT = 0.8\n",
    "EPOCHS = 100\n",
    "\n",
    "import os\n",
    "from donkeycar.parts.datastore import TubGroup\n",
    "from donkeycar.utils import linear_bin\n",
    "\n",
    "def train(tub_path, model_path, log_path):\n",
    "    '''\n",
    "    Convenience method for training using MyEstimator\n",
    "    \n",
    "    Requires the TubGroup class from Donkey to read Tub data.\n",
    "    '''\n",
    "    x_keys = ['cam/image_array']\n",
    "    y_keys = ['user/angle', 'user/throttle']\n",
    "\n",
    "    def rt(record):\n",
    "        record['user/angle'] = linear_bin(record['user/angle'])\n",
    "        return record\n",
    "\n",
    "    tubgroup = TubGroup(tub_names)\n",
    "    train_gen, val_gen = tubgroup.get_train_val_gen(x_keys,\n",
    "                                                    y_keys,\n",
    "                                                    record_transform=rt,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    train_frac=TEST_SPLIT)\n",
    "\n",
    "    model_path = os.path.expanduser(model_name)\n",
    "\n",
    "    total_records = len(tubgroup.df)\n",
    "    total_train = int(total_records * TEST_SPLIT)\n",
    "    total_val = total_records - total_train\n",
    "    print('train: %d, validation: %d' % (total_train, total_val))\n",
    "    steps_per_epoch = total_train // BATCH_SIZE\n",
    "    print('steps_per_epoch', steps_per_epoch)\n",
    "\n",
    "    kl = MyEstimator(log_path)\n",
    "    kl.train(train_gen,\n",
    "             val_gen,\n",
    "             saved_model_path=model_path,\n",
    "             log_path=log_path,\n",
    "             steps=steps_per_epoch,\n",
    "             train_split=TEST_SPLIT,\n",
    "             epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Tub\n",
    "sample_data_location = 's3://jayway-robocar-raw-data/samples'\n",
    "!aws s3 cp {sample_data_location}/ore.zip /tmp/ore.zip\n",
    "!mkdir -pv ~/SageMaker/data\n",
    "!unzip /tmp/ore.zip -d ~/SageMaker/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create output dirs\n",
    "!mkdir -pv ~/SageMaker/models\n",
    "!mkdir -pv ~/SageMaker/logs\n",
    "\n",
    "# Start training\n",
    "tub = '~/SageMaker/data/tub_8_18-02-09'\n",
    "model = '~/SageMaker/models/my-tb-model'\n",
    "logs = '~/SageMaker/logs'\n",
    "train(tub, model, logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "# Accessible from https://<name of notebook instance>/proxy/6006/\n",
    "# Note the '/' at the end of the URL! It will not work without it...\n",
    "!tensorboard --logdir ~/SageMaker/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now access the model graph and training plots by navigating to [https://name-of-notebook instance/proxy/6006/](https://name-of-notebook-instance/proxy/6006/), where *name-of-notebook* is one of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker list-notebook-instances --query 'NotebookInstances[].Url' --output json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go into details about TensorBoard and what you can do with it. We'll leave it up to you to explore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker Estimators](./donkey-sm-estimators.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
