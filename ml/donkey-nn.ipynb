{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Donkey neural network\n",
    "\n",
    "It's time to dig into the neural network code.\n",
    "\n",
    "The goals of this chapter are:\n",
    "- Get familiar with the neural network(s) used in the [Donkey](https://github.com/wroscoe/donkey) library\n",
    "- Make some minor changes to the network and\n",
    "- Create a custom car based on the `donkey/donkeycar/templates/donkey2.py` template\n",
    "\n",
    "If you're running this lab as a part of a workshop, now is a good time to ask the instructor to hold the [ML](../presentations/ai.md) presentation.\n",
    "\n",
    "## Inspecting the Keras network\n",
    "\n",
    "The following code assumes that the [Donkey](https://github.com/wroscoe/donkey) library is properly installed, see [previous chapter](./donkey-train.ipynb#install).\n",
    "\n",
    "First, take a few minutes to look through the `keras.py` file (it's a [Donkey](https://github.com/wroscoe/donkey) library *part*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming donkey library is installed in ./donkey\n",
    "%pycat donkey/donkeycar/parts/keras.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default algorithm used is defined in `donkey/donkeycar/templates/donkey2.py`:\n",
    "\n",
    "```python\n",
    "def drive(cfg, model_path=None, use_joystick=False):\n",
    "    ...\n",
    "    kl = KerasCategorical()\n",
    "    if model_path:\n",
    "        kl.load(model_path)\n",
    "    ...\n",
    "```\n",
    "\n",
    "`KerasCategorical`, which is created in `default_categorical()` method. Before looking closer at the code, let's see if we can visualize it using our pre-trained model (see [previous](./donkey-train.ipynb) chapter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model. Replace bucket if you used some other bucket than SageMaker default\n",
    "import sagemaker\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "!aws s3 cp s3://{bucket}/models/my-first-model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install some additional python libraries required by the Keras visualization lib\n",
    "!conda install --yes pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the algorithm\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('./my-first-model')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! A nice neural network with\n",
    "- 1 input layer\n",
    "- 5 convolutional layers\n",
    "- 1 flatten layer\n",
    "- 2 dense layers\n",
    "- 2 dropout layers\n",
    "\n",
    "The presence of a convolutional layer makes this neural network a [convolutional network](https://en.wikipedia.org/wiki/Convolutional_neural_network). This makes sence, since CNNs are particulary good with images.\n",
    "\n",
    "So, what do the different layers actually do? Let's have a look at them, one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick readup\n",
    "\n",
    "This excellent cheatsheet is handy to read through and use as a reference before continuing:\n",
    "- http://ml-cheatsheet.readthedocs.io/en/latest/nn_concepts.html\n",
    "\n",
    "And two links about CNNs (read, or be confused later):\n",
    "- https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    "- https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input layer\n",
    "\n",
    "The *Input layer* holds the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "# Input layer\n",
    "#\n",
    "# 120 x 160 x 3 image size (RGB)\n",
    "#\n",
    "img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "\n",
    "# Rename it to x\n",
    "x = img_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the shape of the data as a 3 channel (RGB) 120px x 160px image.\n",
    "\n",
    "If you read through the [links](#quick-readup), you'll have a rought idea of what a channel is. In CNNs,  layers operate on 3D chunks of data. The first two dimensions are the height and width of the image, and the third dimension is a number of such 2D data stacked over each other (3 in RGB images). This stack is called channels.\n",
    "\n",
    "Why is this important? In the input layer, a channel is easily understood as RGB data (one channel per color). However, a [convolutional layer](#first-convolutional-layer) can have many more channels, which we'll get to later.\n",
    "\n",
    "Formally, x can be viewed as a $H \\times W \\times C$ vector, where `H,W` are the dimensions of the image and `C` is the number of channels of the given image volume.\n",
    "\n",
    "API documentation:\n",
    "- https://keras.io/layers/core/#input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First convolutional layer\n",
    "\n",
    "Before continuing, make sure you've read through and have a rough idea of the following concepts:\n",
    "- NN concepts - http://ml-cheatsheet.readthedocs.io/en/latest/nn_concepts.html\n",
    "- Relu - http://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#relu\n",
    "- Convolution operator - https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/index.html#convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D\n",
    "\n",
    "# First hidden layer\n",
    "#\n",
    "# 24 features      - Results in a 24 channel feature map(s). This means the first layer can detect 24 different low level features in the image.\n",
    "# 5x5 pixel kernel - Width and height of the kernel. Will automatically have the same channel depth as the input (5x5x3)\n",
    "# 2w x 2h stride   - Strides of the convolution along the width and height\n",
    "# relu activation  - Use the 'relu' activation function\n",
    "#\n",
    "x = Convolution2D(24, (5,5), strides=(2,2), activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first hidden layer is a 2D convolution layer with the described hyperparameters (see above) and a `relu` activation function.\n",
    "\n",
    "> What is the reasoning behind this design? Why are the hyperparameters given these values?\n",
    "\n",
    "This is a tricky question to answer, but important for later tweaking of the network. The sad news are that they often required lots of experience and theoretical background to master. But hey, let's give it a shot!\n",
    "\n",
    "They ar all a tradeoff between performance and accuracy, but there are some general rules to follow. For example, the number of *features* are usually lower in the first convolutional layers, because the input size is still large, resulting in large *feature maps*. Later layers have smaller (but deeper) input size (because of the convolution in the previous layers), and thus can afford to have more features. Similar reasoning can be done for the other hyperparameters. The following link has a more in depth discussion around CNN hyperparameters:\n",
    "- http://deeplearning.net/tutorial/lenet.html#tips-and-tricks\n",
    "\n",
    "API documentation:\n",
    "- https://keras.io/layers/convolutional/#conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second hidden layer\n",
    "#\n",
    "# 32 features      - Results in a 32 channel feature map(s)\n",
    "#\n",
    "x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much changed here. We increase the number of features as discussed earlier. This allows the network to pick up more features based on the feature maps from the first hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third hidden layer\n",
    "#\n",
    "# 64 features      - Results in a 64 channel feature map(s)\n",
    "#\n",
    "x = Convolution2D(64, (5,5), strides=(2,2), activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increase the number of features yet again. The input to the next layer will now be 64 channels deep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth hidden layer\n",
    "#\n",
    "# 3x3 pixel kernel   - Width and height of the kernel. Will automatically have the same channel depth as the input (3x3x64)\n",
    "x = Convolution2D(64, (3,3), strides=(2,2), activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we decrease the kernel size to 3x3. By using a relatively large kernel size in the 3 previous layers, we have shrunk the image size by quite a bit (each convolution will shrink the image/feature map (if not padded), and add depth instead). By decreasing the kernel size, we make sure that image doesn't shrink too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fifth convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth hidden layer\n",
    "#\n",
    "# 1w x 1h stride   -\n",
    "x = Convolution2D(64, (3,3), strides=(1,1), activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last convolution layer, we change the stride length. This will result in larger feature maps (at the cost of performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten \n",
    "\n",
    "# Flatten layer\n",
    "#\n",
    "# Flatten to 1 dimension\n",
    "#\n",
    "x = Flatten(name='flattened')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A flatten layer does what it claims to do. It flattens the convoluted input from 64 channels to 1, by putting the channels after each other. This is needed for the next layer, a fully-connected MLP (Dense).\n",
    "\n",
    "API documentation:\n",
    "- https://keras.io/layers/core/#flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "# First Dense layer\n",
    "#\n",
    "# 100 units       - Use 100 neurons in the layer\n",
    "# relu activation - Use 'relu' activation\n",
    "#\n",
    "x = Dense(100, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dense layer is another name for a fully-connected layer like in a [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron). It is very common for upper-layers in a CNNs to have fully-connected layers (actually, the purpose of conv layers is to extract important features from the image before downsampling enough to be handled by a MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# First dropout\n",
    "#\n",
    "# 0.1 - Randomly drop out 10% of the neurons to prevent overfitting.\n",
    "#\n",
    "x = Dropout(.1)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in the [links](), dropout is used to prevent overfitting by forcing redundancy in the neural network (which means it cannot rely on a particular neuron because it might be dropped)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Dense layer\n",
    "#\n",
    "# 50 units        - Use 50 neurons in the layer\n",
    "#\n",
    "x = Dense(50, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gradually decrease the size of the layers from the original 100 to 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second dropout\n",
    "#\n",
    "# Not much to say here...\n",
    "#\n",
    "x = Dropout(.1)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs\n",
    "#\n",
    "# Angle\n",
    "# Dense              - Fully-connected output layer\n",
    "# 15 units           - Use a 15 neuron output.\n",
    "# softmax activation - Use 'softmax' activation\n",
    "#\n",
    "# Throttle\n",
    "# Dense           - Fully-connected output layer\n",
    "# 1 unit          - Use a 1 neuron output\n",
    "# relu activation - Use 'relu' activation\n",
    "angle_out = Dense(15, activation='softmax', name='angle_out')(x)\n",
    "throttle_out = Dense(1, activation='relu', name='throttle_out')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layers are fully-connected with different units and activations.\n",
    "\n",
    "Angle uses a 15 neuron output with a softmax activation. [Softmax](https://en.wikipedia.org/wiki/Softmax_function) is a common way of creating a probability distribution over K different possible outcomes (in this case, `K=15`).\n",
    "\n",
    "Throttle uses a 1 neuron output with a relu activation. [Relu](https://en.wikipedia.org/wiki/Rectifier_(neural_networks) will result in the throttle having only positive values (it can only go forward)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model\n",
    "\n",
    "Finally, it's time to create the model and define the loss functions for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# Create model\n",
    "#\n",
    "# Optimizer\n",
    "# ---------\n",
    "# adam\n",
    "#\n",
    "# Angle\n",
    "# -----\n",
    "# categorical cross entropy loss function\n",
    "# 0.9 loss weight\n",
    "#\n",
    "# Throttle\n",
    "# --------\n",
    "# mean_absolute_error loss function\n",
    "# 0.001 loss weight\n",
    "# \n",
    "model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'angle_out': 'categorical_crossentropy', 'throttle_out': 'mean_absolute_error'},\n",
    "    loss_weights={'angle_out': 0.9, 'throttle_out': .001})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model requires the following information:\n",
    "- input (`img_in`) and output tensors (`angle_out`, `throttle_out`)\n",
    "- optimizer ([`adam`](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam)). The optimizer is the algorithm used when minimizing the loss function during training. Performs well and efficient.\n",
    "- loss function(s), one for each output\n",
    "  - `angle_out` : [`categorial_crossentropy`](https://en.wikipedia.org/wiki/Cross_entropy) - Suitable for categorization.\n",
    "  - `throttle_out` : [`mean_absolute_error`](https://en.wikipedia.org/wiki/Mean_absolute_error) - More general loss function\n",
    "- initial loss weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Donkey vehicle\n",
    "\n",
    "Puh, that was a lot of one-way information. So, let's actually code something by creating our own `DonkeyCar` with a slightly changed `keras.py`.\n",
    "\n",
    "As mentioned in [earlier chapters](./donkey-tools.ipynb), the [Donkey library](https://github.com/wroscoe/donkey) has several components:\n",
    "- A python library installed in your preferred location (e.g. system python or virtualenv). You `import` it as any other python library, e.g: `import donkeycar as dk`.\n",
    "- A CLI with tools mainly used to aid training (see [donkey-tools.ipynb](./donkey-tools.ipynb))\n",
    "- A `Vehicle` installation, usually installed to the `~/d2` directory. This is where the `manage.py` script is installed, which is used for both **driving** and **training**. The `~/d2` directory and driving the car is discussed further in the [Drive Track](../README.md#the-drive-track).\n",
    "\n",
    "Let's, however, have a look at the **training** part of a Donkey `Vehicle` and `manage.py`. In short, this is what's going on:\n",
    "1. When you install the `Vehicle` to the `~/d2` directory, it is per default installed from the [`donkeycar/templates/donkey2.py`](https://github.com/wroscoe/donkey/blob/master/donkeycar/templates/donkey2.py) template. It creates a `Vehicle` using different Donkey parts.\n",
    "2. Creating `Donkey` parts is more of a focus in the [IoT track](../docs/PREPARE-IOT.md), so we will not dig too deep into what is going on (we leave that for you to sync within the team =)). Examples of parts are Joystick, motor driver and the ML model. See github for more parts: https://github.com/wroscoe/donkey/tree/master/donkeycar/parts\n",
    "3. The installed `Vehicle` has 2 standard methods; `drive()` and `train()` and is invoked using the CLI. \n",
    "  - `drive()` can either be set to manual, and produce training data, or be given a pre-trained model to use when driving autonomously.\n",
    "  - `train()` trains the model using the collected training data (*Tubs*). Usually done in SageMaker (see [previous chapter](./donkey-train.ipynb)) or on the host computer, which requires you to install the library there first.\n",
    "  \n",
    "In this chapter, we'll create a new, simple template for training only, and install it on the training machine (SageMaker or host)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new Donkey part\n",
    "\n",
    "First, we'll create a copy of the model used in training as a new `Donkey` part. Create a file called `cnn.py` in the `donkeycar/parts/` by pasting the following (assuming you have `donkey` in you local directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create a new part. Assumes donkey/ is in current directory\n",
    "cat > donkey/donkeycar/parts/cnn.py << EOF\n",
    "import keras\n",
    "import donkeycar as dk\n",
    "\n",
    "\n",
    "class KerasPilot():\n",
    "\n",
    "    def load(self, model_path):\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "\n",
    "    def shutdown(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, train_gen, val_gen, \n",
    "              saved_model_path, epochs=100, steps=100, train_split=0.8,\n",
    "              verbose=1, min_delta=.0005, patience=5, use_early_stop=True):\n",
    "\n",
    "        save_best = keras.callbacks.ModelCheckpoint(saved_model_path, \n",
    "                                                    monitor='val_loss', \n",
    "                                                    verbose=verbose, \n",
    "                                                    save_best_only=True, \n",
    "                                                    mode='min')\n",
    "        \n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                   min_delta=min_delta, \n",
    "                                                   patience=patience, \n",
    "                                                   verbose=verbose, \n",
    "                                                   mode='auto')\n",
    "\n",
    "        callbacks_list = [save_best]\n",
    "\n",
    "        if use_early_stop:\n",
    "            callbacks_list.append(early_stop)\n",
    "        \n",
    "        hist = self.model.fit_generator(\n",
    "                        train_gen, \n",
    "                        steps_per_epoch=steps, \n",
    "                        epochs=epochs, \n",
    "                        verbose=1, \n",
    "                        validation_data=val_gen,\n",
    "                        callbacks=callbacks_list, \n",
    "                        validation_steps=steps*(1.0 - train_split))\n",
    "        return hist\n",
    "\n",
    "\n",
    "class MyPilot(KerasPilot):\n",
    "    def __init__(self, model=None, *args, **kwargs):\n",
    "        super(MyPilot, self).__init__(*args, **kwargs)\n",
    "        self.model = model if model else default_categorical()\n",
    "        \n",
    "    def run(self, img_arr):\n",
    "        img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
    "        angle_binned, throttle = self.model.predict(img_arr)\n",
    "        angle_unbinned = dk.utils.linear_unbin(angle_binned)\n",
    "        return angle_unbinned, throttle[0][0]\n",
    "\n",
    "\n",
    "def default_categorical():\n",
    "    from keras.layers import Input, Dense, merge\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Convolution2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "    from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "    \n",
    "    img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "    x = img_in\n",
    "    x = Convolution2D(24, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (3,3), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (3,3), strides=(1,1), activation='relu')(x)\n",
    "\n",
    "    x = Flatten(name='flattened')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "    angle_out = Dense(15, activation='softmax', name='angle_out')(x)\n",
    "    throttle_out = Dense(1, activation='relu', name='throttle_out')(x)\n",
    "    \n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'angle_out': 'categorical_crossentropy', \n",
    "                        'throttle_out': 'mean_absolute_error'},\n",
    "                  loss_weights={'angle_out': 0.9, 'throttle_out': .001})\n",
    "\n",
    "    return model\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. As you can see, we've basically just removed some code from `keras.py`. Reinstall the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path with path to where you cloned the donkey git \n",
    "!pip install -e donkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new simple `Vechicle` template used only for training, but tell it to only run 1 epoch (this is only for testing, we don't want to wait for training to finish...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create new Donkey template. Assuming donkey/ is in current directory\n",
    "cat > donkey/donkeycar/templates/robolab.py << EOF\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Scripts to train a donkey 2.\n",
    "\n",
    "Usage:\n",
    "    manage.py (train) [--tub=<tub1,tub2,..tubn>]  (--model=<model>)\n",
    "\n",
    "Options:\n",
    "    -h --help        Show this screen.\n",
    "    --tub TUBPATHS   List of paths to tubs. Comma separated. Use quotes to use wildcards. ie \"~/tubs/*\"\n",
    "\"\"\"\n",
    "import os\n",
    "from docopt import docopt\n",
    "import donkeycar as dk\n",
    "\n",
    "from donkeycar.parts.cnn import MyPilot\n",
    "from donkeycar.parts.datastore import TubGroup\n",
    "\n",
    "\n",
    "def train(cfg, tub_names, model_name):\n",
    "    X_keys = ['cam/image_array']\n",
    "    y_keys = ['user/angle', 'user/throttle']\n",
    "\n",
    "    def rt(record):\n",
    "        record['user/angle'] = dk.utils.linear_bin(record['user/angle'])\n",
    "        return record\n",
    "\n",
    "    kl = MyPilot()\n",
    "    print('tub_names', tub_names)\n",
    "    if not tub_names:\n",
    "        tub_names = os.path.join(cfg.DATA_PATH, '*')\n",
    "    tubgroup = TubGroup(tub_names)\n",
    "    train_gen, val_gen = tubgroup.get_train_val_gen(X_keys, y_keys, record_transform=rt,\n",
    "                                                    batch_size=cfg.BATCH_SIZE,\n",
    "                                                    train_frac=cfg.TRAIN_TEST_SPLIT)\n",
    "\n",
    "    model_path = os.path.expanduser(model_name)\n",
    "\n",
    "    total_records = len(tubgroup.df)\n",
    "    total_train = int(total_records * cfg.TRAIN_TEST_SPLIT)\n",
    "    total_val = total_records - total_train\n",
    "    print('train: %d, validation: %d' % (total_train, total_val))\n",
    "    steps_per_epoch = total_train // cfg.BATCH_SIZE\n",
    "    print('steps_per_epoch', steps_per_epoch)\n",
    "\n",
    "    kl.train(train_gen,\n",
    "             val_gen,\n",
    "             saved_model_path=model_path,\n",
    "             steps=steps_per_epoch,\n",
    "             train_split=cfg.TRAIN_TEST_SPLIT,\n",
    "             epochs=1) # <------ Run only 1 epoch\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = docopt(__doc__)\n",
    "    cfg = dk.load_config()\n",
    "    \n",
    "    if args['train']:\n",
    "        tub = args['--tub']\n",
    "        model = args['--model']\n",
    "        train(cfg, tub, model)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Very nice. Now let's create a new car:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new car using the new template\n",
    "![ -d ~/d3 ] && rm -rfv ~/d3\n",
    "!donkey createcar --template robolab --path ~/d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!cat manage.py\n",
    "\n",
    "# Let's try the new car\n",
    "%cd ~/d3\n",
    "!python manage.py train --tub='../SageMaker/tub_8_18-02-09' --model './models/my-test-model'\n",
    "%cd ~/SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet, seems to work. Now that we now how to create a new template and our own training part, we can improve the network in any way we like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next\n",
    "\n",
    "[Porting Keras](./donkey-porting-keras.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
