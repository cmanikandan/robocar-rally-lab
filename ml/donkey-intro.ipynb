{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Donkey introduction\n",
    "\n",
    "This first tutorial will introduce you to the SageMaker service and its [Jupyter Notebooks](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-notebooks-instances.html).\n",
    "\n",
    "More specifically, we'll have a look at the data format used by the [Donkey](https://github.com/wroscoe/donkey) library when saving training data. The data is generated when you manually drive the car on the track. We'll also play around with some of the more common libraries and data structures available in the Notebooks, such as [pandas](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download sample data\n",
    "\n",
    "We've created some sample data for you start working on, so that you don't have to wait for your car to be ready. Since he sample data is recorded on another car on another track, it might not be representative for you car. However, it will allow you to get started, and it will provide a good foundation for you to continue training once you get data from you own car.\n",
    "\n",
    "Download the sample driving runs, called *Tubs* in Donkey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Bucket location to get training data\n",
    "sample_data_location = 's3://jayway-robocar-raw-data/samples'\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {sample_data_location}/ore.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o ore.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat tub_8_18-02-09/record_3658.json | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and mangle Donkey data\n",
    "\n",
    "In this section, we parse and manipulate the data generated by the [Donkey](https://github.com/wroscoe/donkey/tree/master/donkeycar) library to get familiar with the format.\n",
    "\n",
    "The default configuration will save the captured data in a directory called a *Tub*. A new *Tub* will be created every time a new *drive* session starts.\n",
    "\n",
    "A *Tub* directory contains *records* in JSON format, *images* in JPG format and metadata file, *meta.json*, which specifies the format of the *records*. The default *record* has the following JSON structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"user/angle\": 1.0,\n",
    "   \"cam/image_array\": \"3658_cam-image_array_.jpg\",\n",
    "   \"user/mode\": \"user\",\n",
    "   \"user/throttle\": 0.23455000457777642\n",
    "}\n",
    "```\n",
    "A short description of the properties:\n",
    "- *user/angle* - wheel angle\n",
    "- *user/throttle* - speed\n",
    "- *user/mode* - drive mode (user, local angle, or pilot)\n",
    "- *cam/image_array* - relative reference to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata file specifies the types of the properties in the record files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat tub_8_18-02-09/meta.json | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse data\n",
    "\n",
    "Next, parse the input files into a more suitable format. This snippet will return a list of records, where each record is a dictionary with *angle*, *throttle* and *image*.\n",
    "\n",
    "Take your time to read through the code. There are a few very common libraries introduced in this section, e.g:\n",
    "* `pandas` - Data structures and analysis tools\n",
    "* `PIL` - The Python Image Framework. Nice when working with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def read_tub(path):\n",
    "    '''\n",
    "    Read a Tub directory into memory\n",
    "    \n",
    "    A Tub contains records in json format, one file for each sample. With a default sample frequency of 20 Hz,\n",
    "    a 5 minute drive session will contain roughly 6000 files.\n",
    "    \n",
    "    A record JSON object has the following properties (per default):\n",
    "    - 'user/angle'      - wheel angle\n",
    "    - 'user/throttle'   - speed\n",
    "    - 'user/mode'       - drive mode (.e.g user or pilot)\n",
    "    - 'cam/image_array' - relative path to image\n",
    "    \n",
    "    Returns a list of dicts, [ { 'record_id', 'angle', 'throttle', 'image', } ]\n",
    "    '''\n",
    "\n",
    "    def as_record(file):\n",
    "        '''Parse a json file into a Pandas Series (vector) object'''\n",
    "        return pd.read_json(file, typ='series')\n",
    "    \n",
    "    def is_valid(record):\n",
    "        '''Only records with angle, throttle and image are valid'''\n",
    "        return hasattr(record, 'user/angle') and hasattr(record, 'user/throttle') and hasattr(record, 'cam/image_array')\n",
    "        \n",
    "    def map_record(file, record):\n",
    "        '''Map a Tub record to a dict'''\n",
    "        # Force library to eager load the image and close the file pointer to prevent 'too many open files' error\n",
    "        img = Image.open(os.path.join(path, record['cam/image_array']))\n",
    "        img.load()\n",
    "        # Strip directory and 'record_' from file name, and parse it to integer to get a good id\n",
    "        record_id = int(os.path.splitext(os.path.basename(file))[0][len('record_'):])\n",
    "        return {\n",
    "            'record_id': record_id,\n",
    "            'angle': record['user/angle'],\n",
    "            'throttle': record['user/throttle'],\n",
    "            'image': img\n",
    "        }\n",
    "    \n",
    "    json_files = glob.glob(os.path.join(path, '*.json'))\n",
    "    records = ((file, as_record(file)) for file in json_files)\n",
    "    return list(map_record(file, record) for (file, record) in records if is_valid(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "records = read_tub('tub_8_18-02-09')\n",
    "print('parsed Tub into {} records'.format(len(records)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect\n",
    "\n",
    "Inspect one of the parsed records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(records[100])\n",
    "records[100]['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a matrix\n",
    "\n",
    "Looks legit. Lets merge all the vectors into a matrix with the following format:\n",
    "\n",
    "| record_id    | angle | throttle | image    |\n",
    "| ------------ | ----- | -------- | -------- |\n",
    "| 1            |   0.1 |   0.3    | PIL...   |         \n",
    "| ...          |       |          |          |\n",
    "| n            |       |          |          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(records).set_index('record_id') # Use record_id as index\n",
    "df.sort_index(inplace=True)                                    # Do not create a new copy when sorting\n",
    "pd.set_option('display.max_columns', 10)                       # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)                          # Keep the output on one page\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pandas DataFrame\n",
    "\n",
    "Finally, let's look at some of the properties of the [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/api.html#dataframe) object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the top 5 rows (i.e. not top 5 elements based on label index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to head, but displays the last rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dimensions of the dataframe as a (rows, cols) tuple\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of columns. Equal to df.shape[0]\n",
    "len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array of the column names\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns and their types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axes\n",
    "df.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the frame to a two-dimensional table\n",
    "df.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays descriptive stats for all columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one element returns a Pandas.Series object\n",
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple elements returns a Pandas.DataFrame object\n",
    "df.loc[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing data\n",
    "\n",
    "Let's see if we can make the data a little more visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot throttle only\n",
    "%matplotlib inline\n",
    "\n",
    "df.plot.line(y='throttle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both throttle and angle next to each other\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "df.plot(ax=axes[0], kind='line', y='throttle', color='orange')\n",
    "df.plot(ax=axes[1], kind='density', y='angle', color='red')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice.\n",
    "\n",
    "We can see that throttle seems to be limited to 0.25 (see the [Donkey configuration file](https://github.com/wroscoe/donkey/blob/master/donkeycar/templates/config_defaults.py) for the explanation to that).\n",
    "\n",
    "We can also see that to some extent, the car turns more towards one direction than to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "Let's also have a quick look at the images in the data set. One way is to create a video of all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc, cvtColor, COLOR_RGB2BGR\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def VideoCreator(*args, **kwargs):\n",
    "    v = VideoWriter(*args, **kwargs)\n",
    "    try:\n",
    "        yield v\n",
    "    finally:\n",
    "        v.release()\n",
    "\n",
    "def make_video(images, out='donkey-run.mp4', fps=20):\n",
    "    '''\n",
    "    Creates a video from PIL images\n",
    "    '''\n",
    "    if (len(images) <= 0):\n",
    "      raise ValueError('Images array must not be empty')\n",
    "    \n",
    "    # Extract size from first image\n",
    "    size = images[1].size\n",
    "    \n",
    "    # Create codec\n",
    "    fourcc = VideoWriter_fourcc(*'H264')\n",
    "    \n",
    "    # Create a VideoCreator and return the new video\n",
    "    with VideoCreator(out, fourcc, float(fps), size) as v:\n",
    "        for img in images:\n",
    "            arr = cvtColor(numpy.array(img), COLOR_RGB2BGR)\n",
    "            v.write(arr)\n",
    "\n",
    "    return out\n",
    "\n",
    "video_file = os.path.join('~/SageMaker', make_video(df['image']))\n",
    "print(video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sadly, Jupyter notebooks do not currently support HTML5 video inline (v.5.0.0). You'll have to open it in a new tab:\n",
    "\n",
    "[Run video](./donkey-run.mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "[Donkey library tools](./donkey-tools.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
