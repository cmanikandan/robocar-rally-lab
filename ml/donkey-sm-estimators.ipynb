{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker python SDK\n",
    "\n",
    "In this last chapter we'll have a look at the [SageMaker python SDK](https://github.com/aws/sagemaker-python-sdk), which is an open-sourced python library designed to simplify training and serving (hosting) of ML models on SageMaker.\n",
    "\n",
    "The SDK provides several high-level abstractions to achive this, see the [overview](https://github.com/aws/sagemaker-python-sdk#sagemaker-python-sdk-overview).\n",
    "\n",
    "However, to use the functionality the SDK provides, you have to design your code to use the abstractions provided by the SDK. This might force you to rewrite parts of your already working network/algorithm!\n",
    "\n",
    "## Refactor training script to use the SDK\n",
    "\n",
    "Since the refactoring is quite big, and there are many SDK specific details, it is not possible to have the same level of explenation as in previous chapters. It will be up to you to read up on the SDK if there are parts you don't understand.\n",
    "\n",
    "### Estimators\n",
    "\n",
    "The SageMaker Estimator the abstraction used to train and deploy a model.\n",
    "\n",
    "We'll be using these links as inspiration:\n",
    "- https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/tensorflow_abalone_age_predictor_using_keras\n",
    "- https://cloud.google.com/blog/big-data/2017/12/new-in-tensorflow-14-converting-a-keras-model-to-a-tensorflow-estimator\n",
    "- https://stackoverflow.com/questions/48295788/using-a-keras-model-inside-a-tf-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def read_tub(path):\n",
    "    '''\n",
    "    Read a Tub directory into memory\n",
    "    \n",
    "    A Tub contains records in json format, one file for each sample. With a default sample frequency of 20 Hz,\n",
    "    a 5 minute drive session will contain roughly 6000 files.\n",
    "    \n",
    "    A record JSON object has the following properties (per default):\n",
    "    - 'user/angle'      - wheel angle\n",
    "    - 'user/throttle'   - speed\n",
    "    - 'user/mode'       - drive mode (.e.g user or pilot)\n",
    "    - 'cam/image_array' - relative path to image\n",
    "    \n",
    "    Returns a list of dicts, [ { 'record_id', 'angle', 'throttle', 'image', } ]\n",
    "    '''\n",
    "\n",
    "    def as_record(file):\n",
    "        '''Parse a json file into a Pandas Series (vector) object'''\n",
    "        return pd.read_json(file, typ='series')\n",
    "    \n",
    "    def is_valid(record):\n",
    "        '''Only records with angle, throttle and image are valid'''\n",
    "        return hasattr(record, 'user/angle') and hasattr(record, 'user/throttle') and hasattr(record, 'cam/image_array')\n",
    "        \n",
    "    def map_record(file, record):\n",
    "        '''Map a Tub record to a dict'''\n",
    "        # Force library to eager load the image and close the file pointer to prevent 'too many open files' error\n",
    "        img = Image.open(os.path.join(path, record['cam/image_array']))\n",
    "        img.load()\n",
    "        # Strip directory and 'record_' from file name, and parse it to integer to get a good id\n",
    "        record_id = int(os.path.splitext(os.path.basename(file))[0][len('record_'):])\n",
    "        return {\n",
    "            'record_id': record_id,\n",
    "            'angle': record['user/angle'],\n",
    "            'throttle': record['user/throttle'],\n",
    "            'image': img\n",
    "        }\n",
    "    \n",
    "    json_files = glob.glob(os.path.join(path, '*.json'))\n",
    "    records = ((file, as_record(file)) for file in json_files)\n",
    "    return list(map_record(file, record) for (file, record) in records if is_valid(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Convolution2D\n",
    "from tensorflow.python.keras.layers import Input, Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.estimator import model_to_estimator\n",
    "\n",
    "INPUT_TENSOR_NAME = \"images\"\n",
    "SIGNATURE_NAME = \"serving_default\"\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    '''\n",
    "    Model function for Estimator.\n",
    "    '''\n",
    "    \n",
    "    # 1. Create the model as before, but use features array as input\n",
    "    x = features[INPUT_TENSOR_NAME]\n",
    "    x = Convolution2D(24, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (3,3), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (3,3), strides=(1,1), activation='relu')(x)\n",
    "\n",
    "    x = Flatten(name='flattened')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "\n",
    "    angle_out = Dense(15, activation='softmax', name='angle_out')(x)\n",
    "    throttle_out = Dense(1, activation='relu', name='throttle_out')(x)\n",
    "\n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'angle_out': 'categorical_crossentropy', 'throttle_out': 'mean_absolute_error'},\n",
    "                  loss_weights={'angle_out': 0.9, 'throttle_out': .001})\n",
    "    \n",
    "    # 2. Create the TensorFlow Estimator from the Keras model (Dunno if this gonna work...)\n",
    "    return model_to_estimator(keras_model=model)\n",
    "\n",
    "\n",
    "def train_input_fn(training_dir, params):\n",
    "    # TODO: Need to read a Tub into correct format. Could use read_tub from intro, or Donkey library TubGroup???\n",
    "    records = read_tub(training_dir)\n",
    "    df = pd.DataFrame.from_records(records).set_index('record_id')\n",
    "    \n",
    "    # TODO: Where do we define the input format (nbr of channels):\n",
    "    # img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "    \n",
    "    # Return numpy_input_fn\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={INPUT_TENSOR_NAME: np.array(training_set.data)},\n",
    "        y=np.array(training_set.target),\n",
    "        num_epochs=None,\n",
    "        shuffle=True)()\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    # TODO: Copy/paste train_input_fn\n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={INPUT_TENSOR_NAME: np.array(training_set.data)},\n",
    "        y=np.array(training_set.target),\n",
    "        shuffle=True)()\n",
    "\n",
    "def serving_input_fn(params):\n",
    "    # TODO: Only finish if actually needed. We do not host the endpoint on SageMaker, only train the model\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
