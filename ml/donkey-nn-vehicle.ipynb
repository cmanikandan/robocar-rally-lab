{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Donkey vehicle\n",
    "\n",
    "Puh, [The Donkey Convolutional Neural Network](./donkey-nn.ipynb) was a lot of one-way information. So, let's actually code something by creating our own `DonkeyCar` with a slightly changed `keras.py`.\n",
    "\n",
    "The goals of this chapter are:\n",
    "- To get an introduction to Donkey templates and parts\n",
    "- To isolate the neural network by creating a new `Vehicle` with only code necessary to **train** the neural network. We'll use this knowledge in the later chapters to convert the training script to the [SageMaker SDK](https://github.com/aws/sagemaker-python-sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Donkey library\n",
    "\n",
    "As mentioned before, the [Donkey library](https://github.com/wroscoe/donkey) has several components.\n",
    "\n",
    "It is first and foremost a python library installed where your other python libraries are (e.g. system python or virtualenv). After installation, you can `import` it as any normal python library:\n",
    "\n",
    "```python\n",
    "import donkeycar as dk\n",
    "```\n",
    "\n",
    "It also has a CLI with tools mainly used to aid training (see [donkey-tools.ipynb](./donkey-tools.ipynb)):\n",
    "\n",
    "```bash\n",
    "donkey --help\n",
    "```\n",
    "\n",
    "A `Vehicle` application, installed to the `~/d2` directory by default. This is where you'll find the `manage.py` script, which is used for both **driving** and **training**.\n",
    "\n",
    "```bash\n",
    "~/d2/manage.py --help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Donkey application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also called the `Vehicle` or `Donkey` application and located in the `~/d2` directory.\n",
    "\n",
    "Let's have a look at the **training** part of a Donkey `Vehicle` and `manage.py`. In short, this is what's going on:\n",
    "1. When you install the `Vehicle` to the `~/d2` directory, it is per default installed from the [`donkeycar/templates/donkey2.py`](https://github.com/wroscoe/donkey/blob/master/donkeycar/templates/donkey2.py) template. It creates a `Vehicle` using different Donkey parts.\n",
    "2. Creating `Donkey` parts is more of a focus in the [IoT track](../docs/PREPARE-IOT.md), so we will not dig too deep into what is going on (we leave that for you to sync within the team =)). Examples of parts are Joystick, motor driver and the ML model. See github for more parts: https://github.com/wroscoe/donkey/tree/master/donkeycar/parts\n",
    "3. The installed `Vehicle` has 2 standard methods; `drive()` and `train()` and is invoked using the CLI. \n",
    "  - `drive()` can either be set to manual, and produce training data, or be given a pre-trained model to use when driving autonomously.\n",
    "  - `train()` trains the model using the collected training data (*Tubs*). Usually done in SageMaker (see [previous chapter](./donkey-train.ipynb)) or on the host computer, which requires you to install the library there first.\n",
    "  \n",
    "In this chapter, we'll create a new, simple template for training only, and install it on the training machine (SageMaker or host)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new Donkey part\n",
    "\n",
    "First, we'll create a copy of the model used in training as a new `Donkey` part. Create a file called `cnn.py` in the `donkeycar/parts/` by pasting the following (assuming you have `donkey` in you local directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create a new part.\n",
    "cat > ~/SageMaker/donkey/donkeycar/parts/cnn.py << EOF\n",
    "import keras\n",
    "import donkeycar as dk\n",
    "\n",
    "\n",
    "class KerasPilot():\n",
    "\n",
    "    def load(self, model_path):\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "\n",
    "    def shutdown(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, train_gen, val_gen, \n",
    "              saved_model_path, epochs=100, steps=100, train_split=0.8,\n",
    "              verbose=1, min_delta=.0005, patience=5, use_early_stop=True):\n",
    "\n",
    "        save_best = keras.callbacks.ModelCheckpoint(saved_model_path, \n",
    "                                                    monitor='val_loss', \n",
    "                                                    verbose=verbose, \n",
    "                                                    save_best_only=True, \n",
    "                                                    mode='min')\n",
    "        \n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                   min_delta=min_delta, \n",
    "                                                   patience=patience, \n",
    "                                                   verbose=verbose, \n",
    "                                                   mode='auto')\n",
    "\n",
    "        callbacks_list = [save_best]\n",
    "\n",
    "        if use_early_stop:\n",
    "            callbacks_list.append(early_stop)\n",
    "        \n",
    "        hist = self.model.fit_generator(\n",
    "                        train_gen, \n",
    "                        steps_per_epoch=steps, \n",
    "                        epochs=epochs, \n",
    "                        verbose=1, \n",
    "                        validation_data=val_gen,\n",
    "                        callbacks=callbacks_list, \n",
    "                        validation_steps=steps*(1.0 - train_split))\n",
    "        return hist\n",
    "\n",
    "\n",
    "class MyPilot(KerasPilot):\n",
    "    def __init__(self, model=None, *args, **kwargs):\n",
    "        super(MyPilot, self).__init__(*args, **kwargs)\n",
    "        self.model = model if model else default_categorical()\n",
    "        \n",
    "    def run(self, img_arr):\n",
    "        img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
    "        angle_binned, throttle = self.model.predict(img_arr)\n",
    "        angle_unbinned = dk.utils.linear_unbin(angle_binned)\n",
    "        return angle_unbinned, throttle[0][0]\n",
    "\n",
    "\n",
    "def default_categorical():\n",
    "    from keras.layers import Input, Dense, merge\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Convolution2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "    from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "    \n",
    "    img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "    x = img_in\n",
    "    x = Convolution2D(24, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (3,3), strides=(2,2), activation='relu')(x)\n",
    "    x = Convolution2D(64, (3,3), strides=(1,1), activation='relu')(x)\n",
    "\n",
    "    x = Flatten(name='flattened')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "    angle_out = Dense(15, activation='softmax', name='angle_out')(x)\n",
    "    throttle_out = Dense(1, activation='relu', name='throttle_out')(x)\n",
    "    \n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'angle_out': 'categorical_crossentropy', \n",
    "                        'throttle_out': 'mean_absolute_error'},\n",
    "                  loss_weights={'angle_out': 0.9, 'throttle_out': .001})\n",
    "\n",
    "    return model\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. As you can see, we've basically just removed some code from `keras.py`. Reinstall the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path with path to where you cloned the donkey git \n",
    "!pip install ~/SageMaker/donkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create new Donkey template.\n",
    "cat > ~/SageMaker/donkey/donkeycar/templates/robolab.py << EOF\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Scripts to train a donkey 2.\n",
    "\n",
    "Usage:\n",
    "    manage.py (train) [--tub=<tub1,tub2,..tubn>]  (--model=<model>)\n",
    "\n",
    "Options:\n",
    "    -h --help        Show this screen.\n",
    "    --tub TUBPATHS   List of paths to tubs. Comma separated. Use quotes to use wildcards. ie \"~/tubs/*\"\n",
    "\"\"\"\n",
    "import os\n",
    "from docopt import docopt\n",
    "import donkeycar as dk\n",
    "\n",
    "from donkeycar.parts.cnn import MyPilot\n",
    "from donkeycar.parts.datastore import TubGroup\n",
    "\n",
    "\n",
    "def train(cfg, tub_names, model_name):\n",
    "    X_keys = ['cam/image_array']\n",
    "    y_keys = ['user/angle', 'user/throttle']\n",
    "\n",
    "    def rt(record):\n",
    "        record['user/angle'] = dk.utils.linear_bin(record['user/angle'])\n",
    "        return record\n",
    "\n",
    "    kl = MyPilot()\n",
    "    print('tub_names', tub_names)\n",
    "    if not tub_names:\n",
    "        tub_names = os.path.join(cfg.DATA_PATH, '*')\n",
    "    tubgroup = TubGroup(tub_names)\n",
    "    train_gen, val_gen = tubgroup.get_train_val_gen(X_keys, y_keys, record_transform=rt,\n",
    "                                                    batch_size=cfg.BATCH_SIZE,\n",
    "                                                    train_frac=cfg.TRAIN_TEST_SPLIT)\n",
    "\n",
    "    model_path = os.path.expanduser(model_name)\n",
    "\n",
    "    total_records = len(tubgroup.df)\n",
    "    total_train = int(total_records * cfg.TRAIN_TEST_SPLIT)\n",
    "    total_val = total_records - total_train\n",
    "    print('train: %d, validation: %d' % (total_train, total_val))\n",
    "    steps_per_epoch = total_train // cfg.BATCH_SIZE\n",
    "    print('steps_per_epoch', steps_per_epoch)\n",
    "\n",
    "    kl.train(train_gen,\n",
    "             val_gen,\n",
    "             saved_model_path=model_path,\n",
    "             steps=steps_per_epoch,\n",
    "             train_split=cfg.TRAIN_TEST_SPLIT,\n",
    "             epochs=1) # <------ Run only 1 epoch\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = docopt(__doc__)\n",
    "    cfg = dk.load_config()\n",
    "    \n",
    "    if args['train']:\n",
    "        tub = args['--tub']\n",
    "        model = args['--model']\n",
    "        train(cfg, tub, model)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice. Now let's create a new car:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new car using the new template\n",
    "![ -d ~/d3 ] && rm -rfv ~/d3\n",
    "!donkey createcar --template robolab --path ~/d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!cat manage.py\n",
    "\n",
    "# Let's try the new car\n",
    "%cd ~/d3\n",
    "!python manage.py train --tub='../SageMaker/data/tub_8_18-02-09' --model '../SageMaker/models/my-test-model'\n",
    "%cd ~/SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet, seems to work. Now that we now how to create a new template and our own training part, we can improve the network in any way we like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "[Training in the cloud](./donkey-cloud-train.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
