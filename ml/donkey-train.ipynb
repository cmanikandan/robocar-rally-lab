{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Donkey training\n",
    "\n",
    "Create and train a donkey car using sample data.\n",
    "\n",
    "The training script provided by the [Donkey](https://github.com/wroscoe/donkey) library is optimized to run in a distrubuted way. At best, it can be accelerated by running on a GPU if available. In this tutorial, we'll start with installing and using the library as it comes 'out-of-the-box'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "If you already installed the [Donkey](https://github.com/wroscoe/donkey) library in the [previous chapter](./donkey-tools.ipynb), you can [skip](#Train) this step.\n",
    "\n",
    "Otherwise, go ahead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we're in SageMaker root\n",
    "%cd ~/SageMaker\n",
    "\n",
    "# Remove any old versions of the library\n",
    "!rm -rf ~/SageMaker/donkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Donkey library git\n",
    "!git clone https://github.com/wroscoe/donkey.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is pinned to version 2.0.8 in the Donkey requirements. Change this to allow a newer version\n",
    "!sed -i -e 's/keras==2.0.8/keras>=2.1/g' donkey/setup.py\n",
    "\n",
    "# Install\n",
    "!pip install -e donkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new car using the library CLI\n",
    "!donkey createcar --path ~/d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "### Create a Donkey car application (again)\n",
    "\n",
    "If you haven't already, create a new *Donkey car application* using the default parameters. See [Donkey library tools - createcar](./donkey-tools.ipynb#createcar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!donkey createcar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data (again)\n",
    "\n",
    "Download the sample data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Bucket location to get training data\n",
    "sample_data_location = 's3://jayway-robocar-raw-data/samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {sample_data_location}/ore.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o ore.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model using the Donkey library\n",
    "\n",
    "Start training using the `Donkey car` created in `~/d2/`.\n",
    "\n",
    "The main entrypoint is the `~/d2/manage.py` script, which allows you to start *drive* and *train* sessions. More documentation can be found here:\n",
    "\n",
    "- [http://docs.donkeycar.com/guide/train_autopilot/](http://docs.donkeycar.com/guide/train_autopilot/)\n",
    "\n",
    "**Note!** this training is not accelerated and will take a long time, approximately **30min**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Make sure we're in Donkey car root\n",
    "%cd ~/d2\n",
    "\n",
    "# Start the training\n",
    "!python manage.py train --tub='../SageMaker/tub_8_18-02-09' --model './models/my-first-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting information printed during training:\n",
    "\n",
    "---\n",
    "\n",
    "`joining the tubs 13630 records together. This could take 0 minutes.`\n",
    "\n",
    "Training input is created by joining all records in the *Tub* together.\n",
    "\n",
    "---\n",
    "\n",
    "`train: 10904, validation: 2726`\n",
    "\n",
    "The input is split in 2 sets; *training set* and *validation set*, with an 80/20 percent split.\n",
    "\n",
    "---\n",
    "\n",
    "`steps_per_epoch 85`\n",
    "\n",
    "The number of steps per epoch. One **epoch** is one full pass of the training set. The **epoch** is divided up in **batches**, which basically means that the **weights** of the model are updated after each **batch** in the **epoch**. One **step** is one **batch** long.\n",
    "\n",
    "`steps_per_epoch` is calculated as:\n",
    "\n",
    "$$\n",
    "s = \\frac{t}{b} = \\frac{10904}{128} \\approx 85\n",
    "$$\n",
    "\n",
    "where $s$ is steps per epoch, $t$ is the length of the training set and $b$ is batch size. Batch size is configurable in the `config.py` file as `BATCH_SIZE`. \n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "Epoch 1/100\n",
    "...\n",
    "85/85 [==============================] - 141s 2s/step - loss: 3.1792 - angle_out_loss: 3.5319 - throttle_out_loss: 0.4266 - val_loss: 2.1385 - val_angle_out_loss: 2.3759 - val_throttle_out_loss: 0.2332\n",
    "...\n",
    "```\n",
    "\n",
    "This is the result of 1 epoch of training. A short summary:\n",
    "\n",
    "|                       | Value       | Description |\n",
    "| :-                    | :-          | :-          |\n",
    "| Total epochs          | 100         | The total number of epochs in the training. This is configurable, but not in an easy way |\n",
    "| Time spent            | 141 seconds | The total time spent training this epoch. Since this training is neither accelerated (GPU) nor distributed ( > 1 training instance ), it is very slow. |\n",
    "| Nbr of steps          | 85          | 85 steps per epoch, each step being 128 records long |\n",
    "| loss                  | 3.1792      | The total training loss after the first epoch. This should decrease for each epoch. |\n",
    "| angle_out_loss        | 3.5319      | Training loss for angle. |\n",
    "| throttle_out_loss     | 0.4266      | Training loss for throttle .|\n",
    "| val_loss              | 2.1385      | The total validation loss after the first epoch. This should decrease for each epoch. |\n",
    "| val_angle_out_loss    | 2.3759      | Validation loss for angle. |\n",
    "| val_throttle_out_loss | 0.2332      | Validation loss for throttle. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new model\n",
    "\n",
    "The easiest way to test the model is to use the simulator on your local computer, see [last chapter](./donkey-tools.ipynb#simulator).\n",
    "\n",
    "Download the model. It is outputted to `./models`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la ./models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the model to you local computer, either use an S3 bucket you've already created in the account, or use the default SageMaker bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "dl_bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the model to your bucket\n",
    "!aws s3 cp ./models/my-first-model s3://{dl_bucket}/models/my-first-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download the model to your computer either manually using the AWS console, or using the CLI if you have it configured:\n",
    "```bash\n",
    "aws s3 cp s3://<bucketname>/models/my-first-model .\n",
    "```\n",
    "\n",
    "If you've installed the donkey library properly, you should be able to start the model server using:\n",
    "```bash\n",
    "donkey sim --model=./models/my-first-model --config ~/d2/config.py\n",
    "```\n",
    "\n",
    "If you've installed the simulator properly, you should be able to start it using (on ubuntu):\n",
    "```bash\n",
    "./donkey_sim.x86_64\n",
    "```\n",
    "\n",
    "Finally, click the **NN Steering over Websockets** button, and the car should start driving using the model (not particulary well though)...\n",
    "\n",
    "![simulator button](./simulator-connect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "[Digging into the neural network](./donkey-nn.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
