{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the neural network using the Donkey library\n",
    "\n",
    "In this chapter, you'll create and train the neural network that comes with the [Donkey](https://github.com/wroscoe/donkey) library. It is more or less the same procedure described in the [Donkey docs](http://docs.donkeycar.com/guide/train_autopilot/), only we train on a SageMaker notebook instance and not your local laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Donkey library\n",
    "\n",
    "The [Donkey library](https://github.com/wroscoe/donkey) has several components.\n",
    "\n",
    "It is first and foremost a python library installed where your other python libraries are (e.g. system python or virtualenv). After installation, you can `import` it as any normal python library:\n",
    "\n",
    "```python\n",
    "import donkeycar as dk\n",
    "```\n",
    "\n",
    "It also has a CLI with tools mainly used to aid training (see [donkey-tools.ipynb](./donkey-tools.ipynb)):\n",
    "\n",
    "```bash\n",
    "donkey --help\n",
    "```\n",
    "\n",
    "A `Vehicle` application, installed to the `~/d2` directory by default. This is where you'll find the `manage.py` script, which is used for both **driving** and **training**.\n",
    "\n",
    "```bash\n",
    "~/d2/manage.py --help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Donkey library\n",
    "\n",
    "If you already installed the [Donkey](https://github.com/wroscoe/donkey) library, you can [skip](#Train) this step.\n",
    "\n",
    "Otherwise, go ahead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we're in SageMaker root\n",
    "%cd ~/SageMaker\n",
    "\n",
    "# Remove any old versions of the library\n",
    "!rm -rf ~/SageMaker/donkey\n",
    "\n",
    "# Clone the Donkey library git\n",
    "!git clone https://github.com/wroscoe/donkey.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Donkey dependencies\n",
    "\n",
    "# Keras is pinned to version 2.0.8 in the Donkey requirements. Change this to allow a newer version\n",
    "!sed -i -e 's/keras==2.0.8/keras>=2.1.2/g' ~/SageMaker/donkey/setup.py\n",
    "!sed -i -e 's/tensorflow>=1.1/tensorflow-gpu>=1.4/g' ~/SageMaker/donkey/setup.py\n",
    "\n",
    "# Install\n",
    "!pip uninstall --yes donkeycar\n",
    "!pip install ~/SageMaker/donkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new car using the library CLI\n",
    "!rm -rf ~/d2\n",
    "!donkey createcar --path ~/d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created some sample data for you start working on, so that you don't have to wait for your car to be ready. Since he sample data is recorded on another car on another track, it might not be representative for you car. However, it will allow you to get started, and it will provide a good foundation for you to continue training once you get data from you own car.\n",
    "\n",
    "If you already downloaded the sample data, you can [skip](#Train) this step.\n",
    "\n",
    "Otherwise, go ahead and download the sample driving run, called *Tubs*, in Donkey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Bucket location to get training data\n",
    "sample_data_location = 's3://jayway-robocar-raw-data/samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data directory\n",
    "!mkdir -pv ~/SageMaker/data\n",
    "!aws s3 cp {sample_data_location}/ore.zip ~/SageMaker/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip to data dir\n",
    "!unzip -o ~/SageMaker/data/ore.zip -d ~/SageMaker/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tub size\n",
    "!du -h ~/SageMaker/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model using the Donkey library\n",
    "\n",
    "Start training using the `Donkey car` created in `~/d2/`.\n",
    "\n",
    "The main entrypoint is the `~/d2/manage.py` script, which allows you to start *drive* and *train* sessions. More documentation can be found here:\n",
    "\n",
    "- [http://docs.donkeycar.com/guide/train_autopilot/](http://docs.donkeycar.com/guide/train_autopilot/)\n",
    "\n",
    "**Note!** this training is GPU accelerated since we changed dependencies in the installation step. Otherwise, this is a slow operation, around 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Make sure we're in Donkey car root\n",
    "%cd ~/d2\n",
    "\n",
    "# Start the training\n",
    "!python manage.py train --tub='../SageMaker/data/tub_8_18-02-09' --model './models/my-first-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting information printed during training:\n",
    "\n",
    "---\n",
    "\n",
    "`joining the tubs 13630 records together. This could take 0 minutes.`\n",
    "\n",
    "Training input is created by joining all records in the *Tub* together.\n",
    "\n",
    "---\n",
    "\n",
    "`train: 10904, validation: 2726`\n",
    "\n",
    "The input is split in 2 sets; *training set* and *validation set*, with an 80/20 percent split.\n",
    "\n",
    "---\n",
    "\n",
    "`steps_per_epoch 85`\n",
    "\n",
    "The number of steps per epoch. One **epoch** is one full pass of the training set. The **epoch** is divided up in **batches**, which basically means that the **weights** of the model are updated after each **batch** in the **epoch**. One **step** is one **batch** long.\n",
    "\n",
    "`steps_per_epoch` is calculated as:\n",
    "\n",
    "$$\n",
    "s = \\frac{t}{b} = \\frac{10904}{128} \\approx 85\n",
    "$$\n",
    "\n",
    "where $s$ is steps per epoch, $t$ is the length of the training set and $b$ is batch size. Batch size is configurable in the `config.py` file as `BATCH_SIZE`. \n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "Epoch 1/100\n",
    "...\n",
    "85/85 [==============================] - 141s 2s/step - loss: 3.1792 - angle_out_loss: 3.5319 - throttle_out_loss: 0.4266 - val_loss: 2.1385 - val_angle_out_loss: 2.3759 - val_throttle_out_loss: 0.2332\n",
    "...\n",
    "```\n",
    "\n",
    "This is the result of 1 epoch of training. Values doesn't necessarily match yours. A short summary:\n",
    "\n",
    "|                       | Value       | Description |\n",
    "| :-                    | :-          | :-          |\n",
    "| Total epochs          | 100         | The total number of epochs in the training. This is configurable, but not in an easy way |\n",
    "| Time spent            | 141 seconds | The total time spent training this epoch. Differs depending on instance type and GPU support. |\n",
    "| Nbr of steps          | 85          | 85 steps per epoch, each step being 128 records long |\n",
    "| loss                  | 3.1792      | The total training loss after the first epoch. This should decrease for each epoch. |\n",
    "| angle_out_loss        | 3.5319      | Training loss for angle. |\n",
    "| throttle_out_loss     | 0.4266      | Training loss for throttle .|\n",
    "| val_loss              | 2.1385      | The total validation loss after the first epoch. This should decrease for each epoch. |\n",
    "| val_angle_out_loss    | 2.3759      | Validation loss for angle. |\n",
    "| val_throttle_out_loss | 0.2332      | Validation loss for throttle. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new model\n",
    "\n",
    "The easiest way to test the model is to use the simulator on your local computer, see [Donkey Tools chapter](./donkey-tools.ipynb#Simulator).\n",
    "\n",
    "Download the model. It is outputted to `./models`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la ./models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the model to you local computer, either use an S3 bucket you've already created in the account, or use the default SageMaker bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "dl_bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the model to your bucket\n",
    "!aws s3 cp ./models/my-first-model s3://{dl_bucket}/models/my-first-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download the model to your computer either manually using the AWS console, or using the CLI if you have it configured:\n",
    "```bash\n",
    "aws s3 cp s3://<bucketname>/models/my-first-model .\n",
    "```\n",
    "\n",
    "If you've installed the donkey library properly, you should be able to start the model server using:\n",
    "```bash\n",
    "donkey sim --model=./models/my-first-model --config ~/d2/config.py\n",
    "```\n",
    "\n",
    "If you've installed the simulator properly, you should be able to start it using (on ubuntu):\n",
    "```bash\n",
    "./donkey_sim.x86_64\n",
    "```\n",
    "\n",
    "Finally, click the **NN Steering over Websockets** button, and the car should start driving using the model (not particulary well though)...\n",
    "\n",
    "![simulator button](./simulator-connect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "[Digging into the neural network](./donkey-nn.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
